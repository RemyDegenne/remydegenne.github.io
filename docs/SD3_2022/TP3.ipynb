{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bd3d18",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a8f80",
   "metadata": {},
   "source": [
    "Documentation des librairies utilisées dans ce tp:\n",
    "- scikit-learn: [https://scikit-learn.org/stable/index.html](https://scikit-learn.org/stable/index.html)\n",
    "- matplotlib: [https://matplotlib.org/](https://matplotlib.org/)\n",
    "- numpy: [https://numpy.org/](https://numpy.org/)\n",
    "\n",
    "Instructions d'installation dans un environnement conda, si vous voulez utiliser votre propre ordinateur (inutile de suivre ces instructions sur les machines de la salle info).\n",
    "\n",
    "- Créer un nouvel environnement, appelé `sd3` (vous avez besoin d'avoir anaconda ou miniconda installé)\n",
    "```\n",
    "conda create -n sd3 python=3.9\n",
    "```\n",
    "- Activer l'environnement\n",
    "```\n",
    "conda activate sd3\n",
    "```\n",
    "- Installer les librairies requises\n",
    "```\n",
    "conda install -c conda-forge jupyterlab matplotlib scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e34e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.datasets import load_digits, make_classification, fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb3591",
   "metadata": {},
   "source": [
    "### Données MNIST\n",
    "\n",
    "On va utiliser ici le jeu de données MNIST, qui contient des images de chiffres écrits à la main, représentés par des images en nuances de gris de 28x28 pixels.\n",
    "On peut obtenir ces données grâce au code écrit dans la cellule suivante.\n",
    "L'obtention du jeu de données peut prendre du temps: il est conseillé de n'exécuter ce code qu'une fois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a19db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data\n",
    "Y = mnist.target\n",
    "# On prend un sous-ensemble des données pour accélérer les calculs et rendre le tp plus rapide.\n",
    "# Dans une application réelle, on garderait toutes les données\n",
    "X,Y = shuffle(X,Y)\n",
    "X = X[:10000]\n",
    "Y = Y[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f217ec",
   "metadata": {},
   "source": [
    "- Combien de données sont présentes dans mnist ? Combien de classes ? Afficher quelques exemples à l'aide de la fonction `plot_examples` définie ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6432bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction affiche 4 exemples issus du dataset\n",
    "def plot_examples(data, labels):  # données, étiquettes\n",
    "    _, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "    nb_pxl = len(data[0].flatten())\n",
    "    side_len = int(np.sqrt(nb_pxl))  # taille du côté de l'image (supposée carrée)\n",
    "    for ax, image, label in zip(axes, data, labels):\n",
    "        ax.set_axis_off()\n",
    "        image = image.reshape((side_len, side_len))\n",
    "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "        ax.set_title(\"Label: \" + str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853ac7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ad07ce8",
   "metadata": {},
   "source": [
    "- Séparer l'ensemble de données en trois ensembles: `X_train` avec étiquettes `Y_train` (60% des exemples), `X_val` et `Y_val` (20% des exemples), `X_test` et `Y_test` (20% des exemples). On pourra utiliser la fonction `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd365bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aac5bd3a",
   "metadata": {},
   "source": [
    "L'ensemble de validation va servir à choisir les hyper-paramètres de nos classeurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6edccf",
   "metadata": {},
   "source": [
    "### Le perceptron multi-couches\n",
    "\n",
    "Le perceptron multi-couches (MLP), ou réseau de neurones complètement connecté, est constitué de plusieurs couches de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2fbfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,), activation=\"relu\",\n",
    "    solver=\"sgd\", learning_rate=\"constant\", learning_rate_init=0.001,\n",
    "    max_iter=2000, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa7139",
   "metadata": {},
   "source": [
    "`hidden_layer_sizes=(15,10,)` indique le nombre de neurones dans chaque couche cachée du réseau de neurones. Ici deux couches cachées, avec respectivement 15 et 10 neurones.\n",
    "\n",
    "`activation` décide la fonction d'activation de chaque neurone.\n",
    "\n",
    "`solver` indique la méthode d'apprentissage des poids. \"sgd\" = descente de gradient stochastique.\n",
    "\n",
    "`learning_rate_init` indique la taille de chaque pas de gradient dans la méthode des gradients stochastiques.\n",
    "\n",
    "`max_iter` donne le nombre maximal d'époques de descente de gradient pour l'apprentissage des poids."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b0c84",
   "metadata": {},
   "source": [
    "On peut entrainer le MLP sur les données d'entrainement, puis calculer son score sur des données, par exemple sur les données de validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a3461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.score(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e67e5",
   "metadata": {},
   "source": [
    "Comment peut-on calculer le taux d'erreur du classeur à partir de ce score ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851d96e",
   "metadata": {},
   "source": [
    "### La validation simple\n",
    "\n",
    "Un hyper-paramètre est un paramètre du classeur qui ne change pas au cours de l'apprentissage. Exemple : `learning_rate_init`, `hidden_layer_sizes`, `max_iter`.\n",
    "On peut obtenir la liste complète en utilisant `get_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e05e45",
   "metadata": {},
   "source": [
    "On souhaite trouver les hyper-paramètres qui donnent le meilleur score pour le MLP entrainé. On va utiliser la méthode de \"validation simple\":\n",
    "- On crée une liste de valeurs possibles pour les hyper-paramètres.\n",
    "- Pour chaque valeur dans la liste,\n",
    "    - on entraine (avec `fit`) un MLP avec ces valeurs d'hyper-paramètres sur les données d'entrainement,\n",
    "    - on calcule le score de ce MLP sur les données de validation.\n",
    "- On garde les valeurs d'hyper-paramètres qui donnent le meilleur score\n",
    "- On évalue le MLP obtenu sur les données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516bc864",
   "metadata": {},
   "source": [
    "Utiliser la validation simple pour choisir la meilleure valeur de `learning_rate_init` parmi `[0.1, 0.01, 0.001, 0.0001]`, pour un MLP défini par\n",
    "```\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(10,), activation=\"relu\",\n",
    "    solver=\"sgd\", learning_rate=\"constant\", learning_rate_init=lr,\n",
    "    max_iter=2000, verbose=False)\n",
    "```\n",
    "où `lr` est la valeur de l'hyper-paramètre qu'on optimise.\n",
    "\n",
    "- Afficher une courbe des scores de validation pour chaque valeur de `learning_rate_init`.\n",
    "\n",
    "- Quel est le score du MLP choisi par la validation sur les données de test ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58710c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f72ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec19540",
   "metadata": {},
   "source": [
    "Pour le classeur retenu après validation, tracer une courbe des erreurs d'entrainement et de test au fil de l'apprentissage en utilisant la fonction `partial_fit`. Attention: réinitialiser le mlp avant de procéder à l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df5706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc28675d",
   "metadata": {},
   "source": [
    "Utiliser la validation pour choisir à la fois `learning_rate_init` et le nombre de neurones dans la couche cachée du MLP (utiliser des petites valeurs pour le nombre de neurones, sinon le temps de calcul peut devenir très long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09b1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9de6d42",
   "metadata": {},
   "source": [
    "### Validation croisée avec GridSearchCV\n",
    "\n",
    "La validation croisée est une alternative à la validation simple, plus souvent utilisée.\n",
    "\n",
    "On va utiliser l'objet `GridSearchCV` de scikit-learn.\n",
    "\n",
    "On commence par définir les paramètres qu'on veut essayer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c991670",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'learning_rate_init': [0.0001, 0.001, 0.01], 'hidden_layer_sizes': [(1,), (10,), (15,)],}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c1427",
   "metadata": {},
   "source": [
    "On définit ensuite un classeur `GridSearchCV` à partir d'un MLP, de `tuned_parameters` et d'une fonction de score. Ici `accuracy` correspond au score qu'on a calculé précédemment.\n",
    "\n",
    "Quand on appelle la fonction `fit` de ce classeur, le processus de validation est effectué complètement: toutes les valeurs des hyper-paramètres sont essayées, le score de chaque MLP est calculé et le meilleur modèle est retenu. On peut ensuite obtenir les meilleurs paramètres avec `clf.best_params_`. Le dictionnaire `clf.cv_results_` contient des informations sur le score de chaque MLP essayé.\n",
    "\n",
    "Attention: ce processus peut être très long si `tuned_parameters` contient beaucoup de valeurs. Q: combien de MLP seront entrainés pour le tableau `tuned_parameters` ci-dessus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f889d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(\n",
    "    MLPClassifier(activation=\"relu\",\n",
    "        solver=\"sgd\", learning_rate=\"constant\",\n",
    "        max_iter=2000, verbose=False),\n",
    "    tuned_parameters, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe5436",
   "metadata": {},
   "source": [
    "Entrainer ce classeur et afficher pour chaque hyper-paramètre de la recherche le score du MLP obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07ad00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30088c76",
   "metadata": {},
   "source": [
    "Utiliser la fonction `classification_report(Y_test, Y_pred)` (où le deuxième argument contient les prédictions du classeur) pour examiner la performance du meilleur classeur obtenu. Que signifient les différentes colonnes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a94ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d758988",
   "metadata": {},
   "source": [
    "Question finale: trouver un bon classeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8717e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
